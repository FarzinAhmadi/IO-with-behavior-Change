{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: Load and summarize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pre-processed data csv files\n",
    "raw_users = pd.read_csv(\"data/myfitnesspal/myfitnesspal_users.csv\")\n",
    "raw_foods = pd.read_csv(\"data/myfitnesspal/myfitnesspal_foods.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset contains:\n",
      "   - 9896 unique users with a total of 587187 daily entries\n",
      "   - 6502747 total food entries\n",
      "   - 2133574 unique food entries (different name, serving size and/or nutrients)\n",
      "   - 644887 unique full food names (including brand and flavor)\n"
     ]
    }
   ],
   "source": [
    "# Summarize size of dataset\n",
    "print(\"Dataset contains:\")\n",
    "print(\"   -\", len(raw_users.user_id.unique()), \"unique users with a total of\", len(raw_users), \"daily entries\")\n",
    "print(\"   -\", len(raw_foods), \"total food entries\")\n",
    "just_food = raw_foods.drop(columns=['user_id', 'date', 'meal_name', 'meal_idx'])\n",
    "just_food['full_name'] = just_food[['food_name', 'brand', 'flavor']].apply(lambda row: '_'.join(row.values.astype(str)), axis=1)\n",
    "just_food = just_food.drop_duplicates()\n",
    "print(\"   -\", len(just_food), \"unique food entries (different name, serving size and/or nutrients)\")\n",
    "print(\"   -\", len(just_food['full_name'].unique()), \"unique full food names (including brand and flavor)\")\n",
    "just_food[['full_name', 'food_name', 'brand', 'flavor']].to_csv(\"data/myfitnesspal/unique_foods.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Baseline unique foods from myfitnesspal\n",
    "- Create a dataframe of foods with unique food_name, brand, and flavor which should have the exact same nutritional profile per amount of food\n",
    "- Since nutritional values of these identical foods can still differ slightly after normalization, we take the most frequently entered quantity as the ground truth for the nutritional profile for that unique food\n",
    "- Finally, we scale the nutritional profile of the ground truth to 100 calories, so that all food nutritional profiles are normalized to nutrients per 100 calories to make the clustering in the next step more effective"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database of nutrients normalized per 100 calories\n",
    "norm_food = pd.DataFrame({\n",
    "    'full_name': just_food['full_name'],\n",
    "    'calories': just_food['calories'],\n",
    "    'carbs/100cal': 100 * just_food['carbs'] / just_food['calories'],\n",
    "    'fat/100cal': 100 * just_food['fat'] / just_food['calories'],\n",
    "    'protein/100cal': 100 * just_food['protein'] / just_food['calories'],\n",
    "    'sodium/100cal': 100 * just_food['sodium'] / just_food['calories'],\n",
    "    'sugar/100cal': 100 * just_food['sugar'] / just_food['calories']\n",
    "})\n",
    "\n",
    "# Create new dataframe with average nutrients across identical food names\n",
    "avg_nuts = norm_food.groupby('full_name').mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_nutrients(avg_nuts, grouped_norm_food, just_food, chunk_size=1000):\n",
    "    nutrients = ['carbs/100cal', 'fat/100cal', 'protein/100cal', 'sodium/100cal', 'sugar/100cal']\n",
    "    \n",
    "    print(\"Precomputing value counts...\")\n",
    "    value_counts = {}\n",
    "    for col in tqdm(['serving_size', 'food_name', 'brand', 'flavor'], desc=\"Columns\"):\n",
    "        def safe_mode(x):\n",
    "            counts = x.value_counts()\n",
    "            return counts.index[0] if not counts.empty else np.nan\n",
    "        \n",
    "        value_counts[col] = just_food.groupby('full_name')[col].apply(safe_mode)\n",
    "    \n",
    "    print(\"Adding precomputed values to avg_nuts...\")\n",
    "    for col, counts in value_counts.items():\n",
    "        avg_nuts[col] = avg_nuts['full_name'].map(counts)\n",
    "    \n",
    "    print(\"Initializing columns for best nutrients...\")\n",
    "    for nut in nutrients:\n",
    "        avg_nuts[f'best{nut}'] = np.nan\n",
    "    \n",
    "    def process_group(group, name, avg_row):\n",
    "        if group[nutrients].nunique().eq(1).all():\n",
    "            food_ref = group.iloc[0][nutrients]\n",
    "        else:\n",
    "            dists = ((group[nutrients] - avg_row[nutrients]) / avg_row[nutrients]).abs().sum(axis=1)\n",
    "            food_ref = group.loc[dists.idxmin(), nutrients]\n",
    "        \n",
    "        calories = just_food[just_food['full_name'] == name]['calories'].value_counts().index[0]\n",
    "        return food_ref * (calories / 100)\n",
    "    \n",
    "    print(\"Processing groups in chunks...\")\n",
    "    full_names = list(grouped_norm_food.groups.keys())\n",
    "    \n",
    "    for i in tqdm(range(0, len(full_names), chunk_size), desc=\"Chunks\"):\n",
    "        chunk = full_names[i:i+chunk_size]\n",
    "        chunk_groups = {name: grouped_norm_food.get_group(name) for name in chunk}\n",
    "        \n",
    "        for name, group in chunk_groups.items():\n",
    "            avg_row = avg_nuts[avg_nuts['full_name'] == name].iloc[0]\n",
    "            best_nuts = process_group(group, name, avg_row)\n",
    "            \n",
    "            for nut in nutrients:\n",
    "                avg_nuts.loc[avg_nuts['full_name'] == name, f'best{nut}'] = best_nuts[nut]\n",
    "        \n",
    "        # Clear memory\n",
    "        del chunk_groups\n",
    "    \n",
    "    print(\"Finalizing best_nuts dataframe...\")\n",
    "    food_ref = avg_nuts.drop(columns=nutrients).dropna(how='any')\n",
    "    food_ref = food_ref.rename(columns={\n",
    "        'bestcarbs/100cal': 'carbs', \n",
    "        'bestfat/100cal': 'fat', \n",
    "        'bestprotein/100cal': 'protein', \n",
    "        'bestsodium/100cal': 'sodium',\n",
    "        'bestsugar/100cal': 'sugar'\n",
    "    })\n",
    "    \n",
    "    return food_ref\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process and save standardized nutrient references\n",
    "tqdm.pandas(desc=\"Processing rows\")\n",
    "food_ref = standardize_nutrients(avg_nuts, norm_food.groupby('full_name'), just_food)\n",
    "food_ref.to_csv(\"data/nutrient_reference.csv\")\n",
    "food_ref.to_pickle(\"data/nutrient_reference.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Mapping to USDA FNNDS catetories\n",
    "- Food and Nutrient Database for Dietary Studies (FNDDS) matches NHANES data categorization and includes 5,624 food types: https://fdc.nal.usda.gov/fdc-app.html#/food-search?type=Survey%20(FNDDS)&query="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Code for pre-processing daily entries to match standardized food reference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
